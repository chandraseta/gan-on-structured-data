{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN and Its Variations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN (Generative Adversarial Network) has been hailed as the most interesting idea in the last 10 years of Machine Learning and there have been countless variations of GAN since it came out in 2014. Here is a list of some of its variations and what their specialization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Explanation about mentioned dataset can be found at the end of this notebook_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla GAN - 10 June 2014\n",
    "\n",
    "By Ian Goodfellow et al., without which the other variations would not exist. [arXiv](https://arxiv.org/abs/1406.2661)\n",
    "\n",
    "The first proposed adversarial networks framework, composed of a generator and a discriminator. The generator is trained to generate images from noise input to fool the discriminator. Meanwhile, the discriminator is trained to discriminate real samples from fake samples.\n",
    "\n",
    "Vanilla GAN is highly unstable and difficult to train. GAN is, however, easier to train than other generative models such as Boltzmann Machines since it does not require Monte Carlo approximations.\n",
    "\n",
    "GAN is used on MNIST, TFD, and CIFAR-10 in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CGAN (Conditional GAN) - 6 November 2014\n",
    "\n",
    "By Mehdi Mirza and Simon Osindero. [arXiv](https://arxiv.org/abs/1411.1784)\n",
    "\n",
    "Basically enables GAN to generate data based on certain condition by passing some extra information. The extra information could be class labels to generate data with that specific label. For example, in generating MNIST data, CGAN could produce dataset that represents the number 7 exclusively.\n",
    "\n",
    "CGAN feeds the extra information to both discriminator and generator.\n",
    "\n",
    "CGAN used the MNIST dataset in the research paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCGAN (Deep Convolutional GAN) - 19 November 2015\n",
    "\n",
    "By Alireza Makhzani et al. [arXiv](https://arxiv.org/abs/1511.06434)\n",
    "\n",
    "DCGAN uses multiple convolutional layers on the generator to generate image instead of the normal perceptrons.\n",
    "\n",
    "DCGAN is exclusively used on image datasets (LSUN, Imagenet-1K, Faces (custom dataset))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EBGAN (Energy Based GAN) - 11 September 2016\n",
    "\n",
    "By Junbo Zhao et al. [arXiv](https://arxiv.org/abs/1609.03126v1)\n",
    "\n",
    "EBGAN's discriminator outputs energy value of the data instead of the probability of the data being a real one. Low energy is associated with region near the data manifold.\n",
    "\n",
    "The generator is trained to generate data with low energies, while the discriminator will assign high energies to generated data.\n",
    "\n",
    "EBGAN shows better convergence and scalability, able to generate high-resolution images.\n",
    "\n",
    "EBGAN is used on MNIST, LSUN, and CelebA datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iGAN - 12 September 2016\n",
    "\n",
    "By Jun-Yan Zhu et al. [arXiv](https://arxiv.org/abs/1609.03552)\n",
    "\n",
    "iGAN finds a way to manipulate and even generate images in a realistic manner using GAN. iGAN has its own UI, a canvas where user could transform, recolor, and even add details to images using rough sketches. iGAN will then take over and generate a realistic image based on the changes the user made on the canvas.\n",
    "\n",
    "See iGAN demonstration in [YouTube](https://www.youtube.com/watch?v=9c4z6YsBGQ0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSGAN (Least Squares Generative Adversarial Networks) - 13 November 2016\n",
    "\n",
    "By Xudong Mao et al. [arXiv](https://arxiv.org/abs/1611.04076)\n",
    "\n",
    "LSGAN uses least squares loss function for the discriminator to overcome the vanishing gradient problem during training. Experimental results show that it could generate higher quality image and is more stable than Vanilla GAN.\n",
    "\n",
    "LSGAN is tested on LSUN and HWDB1.0 datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WGAN (Wasserstein GAN) - 26 January 2017\n",
    "\n",
    "By Martin Arjovsky et al. [arXiv](https://arxiv.org/abs/1701.07875)\n",
    "\n",
    "WGAN's discriminator is called critic because it does not explicitly try to classify inputs as real or fake, but measure the Wasserstein distance between the generated data.\n",
    "\n",
    "Wasserstein Distance is a measure of distance between two probability distributions, also known as Earth Mover's (EM) distance.\n",
    "\n",
    "Using EM distance replaces GAN's original Jensen-Shannon (JS) distance. In JS, as the discriminator gets better, the vanishing gradient problem arises. On the other hand, EM is defferentiable almost everywhere and the critic will give clean gradients, avoiding vanishing gradient.\n",
    "\n",
    "Read more about WGAN [in this article by alexirpan](https://www.alexirpan.com/2017/02/22/wasserstein-gan.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRAGAN (Deep Regret Analytic GAN) - 26 Jan 2017\n",
    "\n",
    "By Naveen Kodali et al. [arXiv](https://arxiv.org/abs/1701.07875)\n",
    "\n",
    "DRAGAN aims to improve upon WGAN.\n",
    "\n",
    "DRAGAN uses regret minimization to achieve faster training and improved stability. Similar to WGAN, DRAGAN applies some sort of gradient penalty using the no-regret algorithm to the training process to minimize mode collapse thus increasing stability.\n",
    "\n",
    "DRAGAN is also tested on image dataset (CIFAR-10, MNIST, CelebA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CycleGAN - 30 Mar 2017\n",
    "\n",
    "By Jun-Yan Zhu et al. [arXiv](https://arxiv.org/abs/1703.10593)\n",
    "\n",
    "CycleGAN makes unpaired image-to-image translation possible. Unpaired image-to-image translation means two image dataset with different styles, i.e. real photos and Van Gogh paintings, could be used for style transfer even if the image is not paired. The image from dataset A could be filled with scenery photographs, and the image from dataset B could be filled with Van Gogh's style painting of cats; the model could still learn to do style transfer between dataset A and B.\n",
    "\n",
    "CycleGAN uses the concept of cycle-consistent. Cycle-consistent in language means acquiring the same sentence after translating an English sentence to French and then back again to English. This concept is applied to the image dataset to \n",
    "\n",
    "CycleGAN has 2 Discriminators and 2 Generators, one for each dataset.\n",
    "\n",
    "CycleGAN is used on image for some interesting style transfer, such as horse to zebra, apple to orange, photograph to Monet, and many more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST\n",
    "\n",
    "A collection of handwritten digits, labelled 0-9. Image size is 28x28 pixels, with 1 channel (grayscale).\n",
    "\n",
    "60,000 images in training set, 10,000 in test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFD (Toronto Faces Dataset)\n",
    "\n",
    "A collection of faces with different emotions, labelled Anger, Disgust, Fear, Happy, Sad, Surprise, Neutral. Image size is 32x32 pixels, with 1 channel (grayscale)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSUN (Large-scale Scene Understanding)\n",
    "\n",
    "A collection of scenery photographs, labelled Bedroom, Bridge, Church Outdoor, Classroom, Conference Room, Dining Room, Kitchen, Living Room, Restaurant, Tower. Images are coloured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CelebA (Large-scale CelebFaces Attributes)\n",
    "\n",
    "A collection of celebrity faces, each image is labelled multiple attributes, such as Glasses, Oval Face, Pointy Nose, Mustache. Images are coloured.\n",
    "\n",
    "Each image also has 5 landmark locations and 40 binary attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HWDB1.0\n",
    "\n",
    "A collection of handwritten chinese characters, numbers, and symbols with a total of 3700+ classes. Images are grayscale."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
