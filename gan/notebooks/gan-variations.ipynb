{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN and Its Variations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN (Generative Adversarial Network) has been hailed as the most interesting idea in the last 10 years of Machine Learning and there have been countless variations of GAN since it came out in 2014. Here is a list of some of its variations and what their specialization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Explanation about mentioned dataset can be found at the end of this notebook_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla GAN - 10 June 2014\n",
    "\n",
    "By Ian Goodfellow et al., without which the other variations would not exist. [arXiv](https://arxiv.org/abs/1406.2661)\n",
    "\n",
    "The first proposed adversarial networks framework, composed of a generator and a discriminator. The generator is trained to generate images from noise input to fool the discriminator. Meanwhile, the discriminator is trained to discriminate real samples from fake samples.\n",
    "\n",
    "Vanilla GAN is highly unstable and difficult to train. GAN is, however, easier to train than other generative models such as Boltzmann Machines since it does not require Monte Carlo approximations.\n",
    "\n",
    "GAN is used on MNIST, TFD, and CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CGAN (Conditional GAN) - 6 November 2014\n",
    "\n",
    "By Mehdi Mirza and Simon Osindero. [arXiv](https://arxiv.org/abs/1411.1784)\n",
    "\n",
    "Basically enables GAN to generate data based on certain condition by passing some extra information. The extra information could be class labels to generate data with that specific label. For example, in generating MNIST data, CGAN could produce dataset that represents the number 7 exclusively.\n",
    "\n",
    "CGAN feeds the extra information to both discriminator and generator.\n",
    "\n",
    "CGAN is used on MNIST dataset in the research paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCGAN (Deep Convolutional GAN) - 19 November 2015\n",
    "\n",
    "By Alireza Makhzani et al. [arXiv](https://arxiv.org/abs/1511.06434)\n",
    "\n",
    "DCGAN uses multiple convolutional layers on the generator to generate image instead of the normal perceptrons.\n",
    "\n",
    "DCGAN is exclusively used on image datasets (LSUN, Imagenet-1K, Faces (custom dataset))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EBGAN (Energy Based GAN) - 11 September 2016\n",
    "\n",
    "By Junbo Zhao et al. [arXiv](https://arxiv.org/abs/1609.03126v1)\n",
    "\n",
    "EBGAN's discriminator outputs energy value of the data instead of the probability of the data being a real one. Low energy is associated with region near the data manifold.\n",
    "\n",
    "The generator is trained to generate data with low energies, while the discriminator will assign high energies to generated data.\n",
    "\n",
    "EBGAN is used on MNIST, LSUN, and CelebA datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WGAN (Wasserstein GAN) - 26 January 2017\n",
    "\n",
    "By Martin Arjovsky et al. [arXiv](https://arxiv.org/abs/1701.07875)\n",
    "\n",
    "WGAN's discriminator is called critic because it does not explicitly try to classify inputs as real or fake, but measure the Wasserstein distance between the generated data.\n",
    "\n",
    "Wasserstein Distance is a measure of distance between two probability distributions, also known as Earth Mover's (EM) distance.\n",
    "\n",
    "Using EM distance replaces GAN's original Jensen-Shannon (JS) distance. In JS, as the discriminator gets better, the vanishing gradient problem arises. On the other hand, EM is defferentiable almost everywhere and the critic will give clean gradients, avoiding vanishing gradient.\n",
    "\n",
    "Read more about WGAN [in this article by alexirpan](https://www.alexirpan.com/2017/02/22/wasserstein-gan.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRAGAN (Deep Regret Analytic GAN) - 19 May 2017\n",
    "\n",
    "By Naveen Kodali et al. [arXiv](https://arxiv.org/abs/1701.07875)\n",
    "\n",
    "DRAGAN aims to improve upon WGAN.\n",
    "\n",
    "DRAGAN uses regret minimization to achieve faster training and improved stability. Similar to WGAN, DRAGAN applies some sort of gradient penalty using the no-regret algorithm to the training process to minimize mode collapse thus increasing stability.\n",
    "\n",
    "DRAGAN is also tested on image dataset (CIFAR-10, MNIST, CelebA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST\n",
    "\n",
    "A collection of handwritten digits, labelled 0-9. Image size is 28x28 pixels, with 1 channel (grayscale).\n",
    "\n",
    "60,000 images in training set, 10,000 in test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toronto Faces Dataset (TFD)\n",
    "\n",
    "A collection of faces with different emotions, labelled Anger, Disgust, Fear, Happy, Sad, Surprise, Neutral. Image size is 32x32 pixels, with 1 channel (grayscale)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
